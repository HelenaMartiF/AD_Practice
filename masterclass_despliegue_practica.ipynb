{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Práctica Final: Clasificación con Scikit-learn y MLflow\n",
        "\n",
        "En esta práctica, utilizarás un conjunto de datos de Scikit-learn (podeís usar el mismo que en el notebook de Intro MLFlow) para entrenar un modelo de clasificación.\n",
        "\n",
        "Pasos a seguir: \n",
        "\n",
        "    Exploración de Datos: Analiza el conjunto de datos proporcionado para comprender su estructura y contenido.\n",
        "\n",
        "    Preprocesamiento de Texto: Realiza tareas de preprocesamiento de texto, como tokenización y vectorización, para preparar los datos para el modelado.\n",
        "\n",
        "    Entrenamiento del Modelo: Utiliza algoritmos de clasificación de Scikit-learn para entrenar un modelo con los datos preprocesados.\n",
        "\n",
        "    Evaluación del Modelo: Evalúa el rendimiento del modelo utilizando métricas de evaluación estándar como precisión y recall.\n",
        "\n",
        "    Registro de Métricas con MLflow: Utiliza MLflow para registrar métricas y hiperparámetros durante el entrenamiento, facilitando la gestión y comparación de experimentos.\n",
        "\n",
        "\n",
        "Nota: Dado que no voy a poder tener acceso a vuestros logs de MLFlow añadirme las imagenes de la interfaz de MLFlow en el notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](./img/Comparation.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](./img/Comparation2.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](./img/Metrics.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generar .py de funciones y main con al menos dos argumentos de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import mlflow\n",
        "import argparse\n",
        "import subprocess\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "## Params\n",
        "def params():\n",
        "    parser = argparse.ArgumentParser(description='__main__')\n",
        "    parser.add_argument('--job_name', type=str, help='Project name')\n",
        "    parser.add_argument('--n_estimator_list', nargs='+', type=int, help='List of n_estimators')\n",
        "    parser.add_argument('--model', type=str, help='Model name')\n",
        "    return parser.parse_args()\t\n",
        "\n",
        "## Data loading\n",
        "def data_loading():\n",
        "    data = load_breast_cancer()\n",
        "    df = df = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
        "    df['target'] = data['target']\n",
        "    return df\n",
        "\n",
        "## Data preprocess\n",
        "def data_preprocess(df):\n",
        "    train, test = train_test_split(df, test_size=0.2)\n",
        "    test_target = test['target']\n",
        "    test[['target']].to_csv('test-target.csv', index=False)\n",
        "    del test['target']\n",
        "    test.to_csv('test.csv', index=False)\n",
        "\n",
        "    features = [x for x in list(train.columns) if x != 'target']\n",
        "    x_raw = train[features]\n",
        "    y_raw = train['target']\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x_raw, y_raw,\n",
        "                                                        test_size=.20,\n",
        "                                                        random_state=123,\n",
        "                                                        stratify=y_raw)\n",
        "    return x_train, x_test, y_train, y_test\n",
        "\n",
        "## Model training\n",
        "def mlflow_tracking(nombre_job, x_train, x_test, y_train, y_test, modelos): \n",
        "    print('Ejecutando mlflow_tracking')\n",
        "    \n",
        "    mlflow_ui_process = subprocess.Popen(['mlflow', 'ui', '--port', '5000']) \n",
        "    print(mlflow_ui_process)\n",
        "    time.sleep(5)\n",
        "    \n",
        "    mlflow.set_experiment(nombre_job) \n",
        "    \n",
        "    for model_name, model_instance in modelos:\n",
        "        with mlflow.start_run() as run:\n",
        "            print(f\"Entrenando modelo: {model_name}\")\n",
        "            \n",
        "            preprocessor = Pipeline(steps=[('scaler', StandardScaler())])\n",
        "            model = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                     ('classifier', model_instance)])\n",
        "            \n",
        "            model.fit(x_train, y_train)\n",
        "            \n",
        "            accuracy_train = model.score(x_train, y_train)\n",
        "            accuracy_test = model.score(x_test, y_test)\n",
        "            y_pred = model.predict(x_test)\n",
        "            precision = precision_score(y_test, y_pred)\n",
        "            recall = recall_score(y_test, y_pred)\n",
        "            f1 = f1_score(y_test, y_pred)\n",
        "            roc_auc = roc_auc_score(y_test, model.predict_proba(x_test)[:, 1])\n",
        "\n",
        "            mlflow.set_tag(\"mlflow.runName\", f\"{model_name}-experiment\")\n",
        "            \n",
        "            mlflow.log_param('modelo', model_name)\n",
        "            mlflow.log_metric('accuracy_train', accuracy_train)\n",
        "            mlflow.log_metric('accuracy_test', accuracy_test)\n",
        "            mlflow.log_metric('precision', precision)\n",
        "            mlflow.log_metric('recall', recall)\n",
        "            mlflow.log_metric('f1_score', f1)\n",
        "            mlflow.log_metric('roc_auc', roc_auc)\n",
        "            \n",
        "            mlflow.sklearn.log_model(model, f'{model_name}-model')\n",
        "            \n",
        "            print(f\"{model_name} successfully registered.\")\n",
        "    \n",
        "    print(\"All models were successfully trained.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "from functions import params, data_loading, data_preprocess, mlflow_tracking\n",
        "\n",
        "def main():\n",
        "    print(\"Ejecutando main\")\n",
        "    args_values = params()\n",
        "    df = data_loading()\n",
        "    x_train, x_test, y_train, y_test = data_preprocess(df)\n",
        "    \n",
        "    # Lista de modelos para probar\n",
        "    models = [\n",
        "        ('RandomForest', RandomForestClassifier(n_estimators=100, random_state=123)),\n",
        "        ('LogisticRegression', LogisticRegression(max_iter=1000, random_state=123)),\n",
        "        ('DecisionTree', DecisionTreeClassifier(random_state=123)),\n",
        "        ('SVC', SVC(probability=True, random_state=123))\n",
        "    ]\n",
        "    \n",
        "    # Llama a la función de tracking con los modelos\n",
        "    mlflow_tracking(args_values.job_name, x_train, x_test, y_train, y_test, models)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Práctica parte FastAPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Para esta parte de la práctica teneis que generar un script con al menos 5 modulos app.get y dos de ellos tienen que ser pipelines de HF. \n",
        "\n",
        "### Parte de la practica se tendra que entregar en capturas de pantalla. Las capturas de pantalla a adjuntas son las siguientes. \n",
        "\n",
        "### 1. Captura de la pantalla docs con al menos 5 modulos. \n",
        "### 2. Captura de cada una de los modulos con la respuesta dentro de docs. \n",
        "### 3. Captura de cada uno de los modulos en la llamada https.\n",
        "### 4. Todo el codigo usado durante el proceso. Notebooks y scripts.\n",
        "\n",
        "### Opcional\n",
        "\n",
        "### 5. Despliegue del script en GCP Cloud Run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](./img/1.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](./img/2.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](./img/3.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](./img/4.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](./img/5.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](./img/5.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](./img/6.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](./img/7.PNG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import Optional\n",
        "import pandas as pd \n",
        "import requests\n",
        "from transformers import pipeline\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"message\": \"Running correctly. Welcome.\"}\n",
        "\n",
        "@app.get(\"/sentiment\")\n",
        "def sentiment_classifier(query: str):\n",
        "    sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "    result = sentiment_pipeline(query)\n",
        "    return {\"Sentiment\": result[0]['label'], \"Confidence\": result[0]['score']}\n",
        "\n",
        "@app.get(\"/summary\")\n",
        "def summarize_text(query: str):\n",
        "    summarizer = pipeline(\"summarization\")\n",
        "    summary = summarizer(query)\n",
        "    return {\"Summary\": summary[0]['summary_text']}\n",
        "\n",
        "\n",
        "\n",
        "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\", aggregation_strategy=\"simple\")\n",
        "class TextRequest(BaseModel):\n",
        "    text: str\n",
        "\n",
        "def convert_to_serializable(result):\n",
        "    for entity in result:\n",
        "        entity['score'] = float(entity['score'])\n",
        "    return result\n",
        "\n",
        "@app.post(\"/ner\")\n",
        "def ner(request: TextRequest):\n",
        "    \"\"\"\n",
        "    Realiza el reconocimiento de entidades nombradas (NER) sobre un texto.\n",
        "    \"\"\"\n",
        "    result = ner_pipeline(request.text)\n",
        "    result = convert_to_serializable(result) \n",
        "    return {\"entities\": result}\n",
        "\n",
        "\n",
        "RIOT_API_KEY = \"RGAPI-fb264af6-4732-4a13-a547-06a5f2c5ea6e\"\n",
        "RIOT_API_URL = \"https://ddragon.leagueoflegends.com/cdn/12.20.1/data/en_US/champion.json\"  \n",
        "\n",
        "@app.get(\"/LoL/champion/{champion_name}\")\n",
        "def get_champion_habilities(champion_name: str):\n",
        "    \"\"\"\n",
        "    Obtener información sobre un campeón específico, incluidas sus habilidades.\n",
        "    \"\"\"\n",
        "    url = f\"https://ddragon.leagueoflegends.com/cdn/12.20.1/data/en_US/champion/{champion_name}.json\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        champion_data = response.json()\n",
        "        abilities = champion_data.get(\"data\", {}).get(champion_name, {}).get(\"spells\", [])\n",
        "        \n",
        "        skills = []\n",
        "        for ability in abilities:\n",
        "            skills.append({\n",
        "                \"name\": ability.get(\"name\"),\n",
        "                \"description\": ability.get(\"description\")\n",
        "            })\n",
        "\n",
        "        return {\"champion\": champion_name, \"skills\": skills}\n",
        "    else:\n",
        "        return {\"error\": f\"Champion {champion_name} not found\"}\n",
        "    \n",
        "@app.get(\"/LoL/champions\")\n",
        "def get_champions():\n",
        "    \"\"\"\n",
        "    Obtener lista de campeones disponibles.\n",
        "    \"\"\"\n",
        "    response = requests.get(RIOT_API_URL)\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        champions_data = response.json()\n",
        "        champions = champions_data.get(\"data\", {})\n",
        "        champion_names = list(champions.keys())\n",
        "        return {\"champions\": champion_names}\n",
        "    else:\n",
        "        return {\"error\": \"Could not retrieve champion data\"}\n",
        "    \n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
